{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2526bbf-91ed-4a1d-be5e-7514682264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasharing.datasharing import DataSharingClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3ec309-5c89-4afa-b122-2772b97d5c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pl.Config.set_tbl_rows(100) \n",
    "pl.Config.set_tbl_cols(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73169549-d898-4632-91fc-22e39d55dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n",
      "Getting identity ID...\n",
      "Identity ID obtained: us-east-1:965f31bc-4398-ceed-80d7-4c23051bccb6\n",
      "Getting OpenID token...\n",
      "OpenID token obtained.\n",
      "Getting credentials for identity...\n",
      "Temporary credentials obtained.\n",
      "DuckDB setup complete.\n",
      "View francetax created.\n"
     ]
    }
   ],
   "source": [
    "client = DataSharingClient(debug=True)\n",
    "\n",
    "local_path = 'C:/Users/lazzz/PycharmProjects/datasharing/data_used/francetax.parquet'\n",
    "view_name = \"francetax\"\n",
    "client.create_view(local_path, view_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f6215-3e15-41b0-94a8-7d8c562087f7",
   "metadata": {},
   "source": [
    "# Fix missing INSEE codes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9cb927a-6ffc-4285-9026-0c2cf0bea297",
   "metadata": {},
   "source": [
    "query =\"\"\"SELECT DISTINCT\n",
    "    REPLACE(REPLACE(\"Libellé commune\", '-', ' '), '''', '') AS name,\n",
    "    \"code INSEE\",\n",
    "    CASE \n",
    "        WHEN DEPARTEMENT IN ('96', '98', '99') THEN CONCAT('97', RIGHT(DEPARTEMENT, 1))\n",
    "        ELSE LTRIM(DEPARTEMENT, '0')\n",
    "    END AS DEPARTEMENT,\n",
    "    CASE \n",
    "        WHEN DEPARTEMENT IN ('96', '98', '99') AND LENGTH(COMMUNE) = 3 THEN RIGHT(COMMUNE, 2)\n",
    "        WHEN COMMUNE = '999' THEN '56'\n",
    "        ELSE REPLACE(COMMUNE, '''', '')\n",
    "    END AS COMMUNE\n",
    "FROM (\n",
    "    SELECT \n",
    "        \"Libellé commune\",\n",
    "        \"code INSEE\",\n",
    "        LTRIM(REPLACE(DEPARTEMENT, '\\n', ''), '0') AS DEPARTEMENT,\n",
    "        CAST(COMMUNE AS VARCHAR) AS COMMUNE\n",
    "    FROM francetax\n",
    ") AS cleaned_data;\n",
    "\"\"\"\n",
    "commune_code = client.query(query=query)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f86d2b30-b151-4e47-8561-5dda783dbfff",
   "metadata": {},
   "source": [
    "def create_insee_code(department, commune):\n",
    "    if len(department) <= 2:\n",
    "      # Ensure department code is 2 digits\n",
    "        return f\"{department.zfill(2)}{commune.zfill(3)}\"\n",
    "    else:\n",
    "        return f\"{department}{commune.zfill(2)}\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "61bcd76f-f21a-43d5-a1be-beecd327c46f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "commune_code = commune_code.astype('string')\n",
    "commune_code['code INSEE'] = commune_code.apply(lambda row: create_insee_code(row['DEPARTEMENT'], row['COMMUNE']), axis=1)\n",
    "commune_code.drop_duplicates('code INSEE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01085c-143c-47bf-9fd2-a9eb0bdd7de3",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218736d8-064d-4fe4-9ba6-9aec021a8998",
   "metadata": {},
   "source": [
    "## Which columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f668e4c-5486-4ca9-93ae-98067fdb3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT column_name\n",
      "FROM INFORMATION_SCHEMA.COLUMNS\n",
      "WHERE table_name = 'francetax';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"SELECT column_name\n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE table_name = 'francetax';\n",
    "\"\"\"\n",
    "column_names = client.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389ba8ab-44c2-4c48-9129-826c7578d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE ORDER OF TAXES\n",
    "\n",
    "tax_types = [\n",
    "    \"FNB\",\n",
    "    \"TAFNB\",\n",
    "    \"FB\",\n",
    "    \"TH\",\n",
    "    \"CFE\",\n",
    "    \"CVAE\", \n",
    "]\n",
    "y_columns = [\n",
    "    \"FNB - COMMUNE / MONTANT REEL\",\n",
    "    \"TAFNB - COMMUNE / MONTANT REEL NET\",\n",
    "    \"FB - COMMUNE / MONTANT REEL\",\n",
    "    \"TH - COMMUNE / MONTANT REEL DONT THP/E AU PROFIT DE L ETAT\",\n",
    "    \"CFE - COMMUNE / PRODUIT REEL NET\",\n",
    "    \"Part de CVAE au profit de la commune\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585d3d81-7c44-45d2-bc40-27d28ee9d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_prediction = {}\n",
    "for tax in tax_types:\n",
    "    # find columns, which contain tax type in their name, return as list to dict\n",
    "    matching_columns = column_names[column_names['column_name'].str.contains(r'\\b' + re.escape(tax) + r'\\b', regex=True, case=False)]['column_name'].tolist()\n",
    "    # Exclude columns that are in y_columns\n",
    "    # matching_columns = [col for col in matching_columns if col not in y_columns]\n",
    "    dict_col_prediction[tax] = matching_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8522024-91ba-4bb1-9b40-6d50cb6c7538",
   "metadata": {},
   "source": [
    "## EXCLUDE TEOM, IFER, TASCOM because target columns are almos empty"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4b1059d-1f95-4b14-b098-2a20e0d4909a",
   "metadata": {},
   "source": [
    "zero_percentage\n",
    "TASCOM au profit de la commune\tTASCOM au profit du GFP\n",
    "f64\tf64\n",
    "0.989822\t0.928973\n",
    "\n",
    "\n",
    "shape: (1,)\n",
    "Series: 'FNB - COMMUNE / MONTANT REEL' [f64]\n",
    "[\n",
    "\t0.001703\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'TAFNB - COMMUNE / MONTANT REEL NET' [f64]\n",
    "[\n",
    "\t0.695893\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'FB - COMMUNE / MONTANT REEL' [f64]\n",
    "[\n",
    "\t0.001724\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'TH - COMMUNE / MONTANT REEL DONT THP/E AU PROFIT DE L ETAT' [f64]\n",
    "[\n",
    "\t0.074248\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'CFE - COMMUNE / PRODUIT REEL NET' [f64]\n",
    "[\n",
    "\t0.064263\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'Part de CVAE au profit de la commune' [f64]\n",
    "[\n",
    "\t0.709434\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'Valeur locative moyenne TEOM N - COMMUNE' [f64]\n",
    "[\n",
    "\t0.977134\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'IFER TOTALE / COMMUNE' [f64]\n",
    "[\n",
    "\t0.957805\n",
    "]\n",
    "shape: (1,)\n",
    "Series: 'TASCOM au profit de la commune' [f64]\n",
    "[\n",
    "\t0.722326\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb40be-b0e5-4737-9cba-557953c080d8",
   "metadata": {},
   "source": [
    "## Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7193f39e-ce81-4b80-b685-a4d6d2d43667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldata_pl = pl.read_parquet('data_used/francetax.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39bbbda-69b8-4e3e-a601-d4e5cbec9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# francetax = pl.scan_parquet('data_used/francetax.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "606d1043-232f-4655-aae4-8062b8c89692",
   "metadata": {},
   "outputs": [],
   "source": [
    "francetax = pl.scan_parquet('data_used/francetax.parquet').with_columns(\n",
    "    # Replace - ' in commune names\n",
    "    pl.col(\"Libellé commune\").str.replace(\"-\", \" \").str.replace(\"'\", \"\").alias(\"Commune name\"),\n",
    "    # Fix DEPARTEMENT column => replace \\n symbols and 0, [\"96\", \"98\", \"99\"] == 97*\n",
    "    pl.when(pl.col(\"DEPARTEMENT\").cast(pl.Utf8).str.replace(\"\\n\", \"\").str.replace(r\"^0+\", \"\").is_in([\"96\", \"98\", \"99\"]))\n",
    "    .then(pl.concat_str([pl.lit(\"97\"), pl.col(\"DEPARTEMENT\").cast(pl.Utf8).str.replace(\"\\n\", \"\").str.replace(r\"^0+\", \"\").str.slice(-1)]))\n",
    "    .otherwise(pl.col(\"DEPARTEMENT\").cast(pl.Utf8).str.replace(\"\\n\", \"\").str.replace(r\"^0+\", \"\")).alias(\"DEPARTEMENT\"),\n",
    "    # Fix COMMUNE column\n",
    "    pl.when((pl.col(\"DEPARTEMENT\").cast(pl.Utf8).str.replace(\"\\n\", \"\").str.replace(r\"^0+\", \"\").is_in([\"96\", \"98\", \"99\"])) & (pl.col(\"COMMUNE\").cast(pl.Utf8).str.len_chars() == 3))\n",
    "    .then(pl.col(\"COMMUNE\").cast(pl.Utf8).str.slice(-2))\n",
    "    .when(pl.col(\"COMMUNE\") == 999)\n",
    "    .then(pl.lit(\"56\"))\n",
    "    .otherwise(pl.col(\"COMMUNE\").cast(pl.Utf8).str.replace(\"'\", \"\"))\n",
    "    .alias(\"COMMUNE\")\n",
    ")\n",
    "basic_columns = ['Commune name', 'DEPARTEMENT', 'COMMUNE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70fc2f59-cdc6-43e4-ae5b-0f5c52dcfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_insee_code(department, commune):\n",
    "    # Define conditions and actions for creating the INSEE code\n",
    "    condition = department.str.len_chars() <= 2\n",
    "    action1 = department.str.zfill(2) + commune.str.zfill(3)\n",
    "    action2 = department + commune.str.zfill(2)\n",
    "    # Use a ternary expression to apply the appropriate action\n",
    "    insee_code = pl.when(condition).then(action1).otherwise(action2)\n",
    "    return insee_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3eda41-5333-442b-a08a-5f6ed709b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "commune_code = francetax.select(*basic_columns).collect()\n",
    "\n",
    "commune_code = commune_code.with_columns([\n",
    "    create_insee_code(commune_code['DEPARTEMENT'], commune_code['COMMUNE']).alias(\"code INSEE\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede0bfc-e65d-4cf3-a834-f8bfea764bc8",
   "metadata": {},
   "source": [
    "## Query and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba872097-7450-4fa9-b67e-dc3e3e742c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = {}\n",
    "for tax, columns in dict_col_prediction.items():\n",
    "    pred_data[tax] = francetax.select(*basic_columns, *columns).with_columns([\n",
    "    create_insee_code(commune_code['DEPARTEMENT'], commune_code['COMMUNE']).alias(\"code INSEE\")\n",
    "]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552a63b6-841e-4f0d-bdef-70153854d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax, data in pred_data.items():\n",
    "    # Identify columns with Utf8 dtype\n",
    "    utf8_columns = [col for col in data.columns if data[col].dtype == pl.Utf8]\n",
    "    utf8_columns.remove('Commune name')\n",
    "    utf8_columns.remove('DEPARTEMENT')\n",
    "    utf8_columns.remove('code INSEE')\n",
    "    utf8_columns.remove('COMMUNE')\n",
    "    # if tax == 'TEOM':\n",
    "    #     utf8_columns.remove('Bénéficiaire de la TEOM (C, I, P ou S)')\n",
    "    #     utf8_columns.remove('Libellé du syndicat TEOM')\n",
    "    #     utf8_columns.remove('NUMERO SIREN DU SYNDICAT TEOM')\n",
    "    # Apply transformations to all relevant columns\n",
    "    try:\n",
    "        pred_data[tax] = data.with_columns([\n",
    "            pl.when(pl.col(col).is_in([\".\", \"'\", \",\"]))\n",
    "            .then(None)\n",
    "            .otherwise(\n",
    "                pl.col(col)\n",
    "                .str.replace(',', '.')\n",
    "                \n",
    "            ).alias(col).cast(pl.Float64)\n",
    "            for col in utf8_columns\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tax}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880401a4-1a61-4dda-8769-360374e72a1e",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418dc37b-7f53-4c92-bfa6-a75be3a6d89f",
   "metadata": {},
   "source": [
    "## Predict same year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b99009-759c-4922-a71f-08de6cddd109",
   "metadata": {},
   "source": [
    "### Clear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94132db9-0a01-4d44-bf8f-cee5a1b46587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null_columns(df: pl.DataFrame, threshold: float = 0.5) -> list:\n",
    "    total_rows = df.height\n",
    "    null_counts = df.null_count().unpivot()\n",
    "    \n",
    "    result = (\n",
    "        null_counts\n",
    "        .filter(pl.col('value') / total_rows > threshold)\n",
    "        .select('variable')\n",
    "        .to_series()\n",
    "        .to_list()\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "882dfe2e-2d6c-4119-9b49-02c57c5729b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with completeness < 80%\n",
    "for tax, data in pred_data.items():\n",
    "    for i in find_null_columns(data, 0.8):\n",
    "        data.drop_in_place(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b450d44c-4d12-47ef-a921-cf300bf42ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_column_dict = dict(zip(tax_types, y_columns))\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    pred_data[tax] = pred_data[tax].filter(pl.col(target_column).is_not_null())\n",
    "    \n",
    "    pred_data[tax] = pred_data[tax].select(pl.all().exclude('Commune name',\t'DEPARTEMENT', 'COMMUNE', 'code INSEE'))\n",
    "    pred_data[tax] = pred_data[tax].drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc4c6bd7-6c1f-4e48-8551-7f6b0cfe07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax, target_column in tax_column_dict.items():\n",
    "    # Step 1: Filter rows where the target column is not null\n",
    "    pred_data[tax] = (\n",
    "        pred_data[tax]\n",
    "        .filter(pl.col(target_column).is_not_null())\n",
    "        .select(pl.all().exclude('Commune name', 'DEPARTEMENT', 'COMMUNE', 'code INSEE'))\n",
    "        .drop_nulls()\n",
    "    )\n",
    "\n",
    "    # Step 2 & 3: Calculate the percentage of zero values for each column\n",
    "    total_rows = pred_data[tax].height\n",
    "    zero_percentage = pred_data[tax].select([\n",
    "        ((pl.col(col) == 0).sum() / total_rows).alias(col)\n",
    "        for col in pred_data[tax].columns\n",
    "    ])\n",
    "    \n",
    "    # print(tax, zero_percentage)\n",
    "    # Step 4: Keep only columns where less than 95% of the values are zero\n",
    "    columns_to_keep = zero_percentage.unpivot().filter(\n",
    "        pl.col(\"value\") < 0.95\n",
    "    ).select(\"variable\").to_series().to_list()\n",
    "\n",
    "    # Step 5: Select only the columns to keep\n",
    "    pred_data[tax] = pred_data[tax].select(columns_to_keep)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608302c-e6c3-4a65-9e61-35cfda7db6e5",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9d54a-2484-4807-91a0-7413a02ce7c9",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e54c888-2946-4583-9f17-b7a12543685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate decision tree regressor\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "tree_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    tree_models[tax] = train_evaluate_model(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7adef970-bc18-4dd7-89c7-4fd8912173e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873.05\n",
      "4.29\n",
      "27838.20\n",
      "77756.47\n",
      "4225.08\n",
      "690.51\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, (model, mae_test, r2_test, mae_val, r2_val) in tree_models.items():\n",
    "    # print(tax)\n",
    "    print(f'{mae_test:.2f}')\n",
    "    # print(f'{r2_test*100:.2f}%')\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(f\"Test set - MSE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "    # print(f\"Validation set - MSE: {mae_val:.4f}, R2: {r2_val:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e37f4291-fb0a-4918-b3f3-e7f8aa00f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate decision tree regressor\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "tree_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    tree_models[tax] = train_evaluate_model(X_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21761c91-4a09-43da-8782-a91d4a268308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FNB': (DecisionTreeRegressor(), 793.4263077037441, 0.990036247839628),\n",
       " 'TAFNB': (DecisionTreeRegressor(), 4.133356197777793, 0.993969738855649),\n",
       " 'FB': (DecisionTreeRegressor(), 39646.460659566226, 0.8791926567616005),\n",
       " 'TH': (DecisionTreeRegressor(), 99414.51001624255, 0.9959456901462556),\n",
       " 'CFE': (DecisionTreeRegressor(), 2948.9011406844106, 0.9997594293266302),\n",
       " 'CVAE': (DecisionTreeRegressor(), 1195.3781331391604, 0.9930968841320498)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700ac6f-51ab-4874-8b53-c3f8cffe4af1",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad2d5c88-e9c2-4665-a39c-7ada7bd55d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "lin_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    lin_models[tax] = train_evaluate_model(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2ad0c68-7241-4683-925a-3f5b1ed1dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.62%\n",
      "22.90%\n",
      "95.49%\n",
      "100.00%\n",
      "92.42%\n",
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, (model, mae_test, r2_test, mae_val, r2_val) in lin_models.items():\n",
    "    # print(tax)\n",
    "    # print(f'{r2_val:.2f}')\n",
    "    print(f'{r2_val*100:.2f}%')\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(f\"Test set - MSE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "    # print(f\"Validation set - MSE: {mae_val:.4f}, R2: {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fbc4d4b-de2f-4202-99dc-e02d13405ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "        \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "lin_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    lin_models[tax] = train_evaluate_model(X_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed3e17e5-4729-404d-b612-3a36e6d0f0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FNB': (LinearRegression(), 2284.250287146987, 0.9707233150151118),\n",
       " 'TAFNB': (LinearRegression(), 354.58604633532946, 0.30478243880946176),\n",
       " 'FB': (LinearRegression(), 164493.1441822689, 0.9401209022988952),\n",
       " 'TH': (LinearRegression(), 39947.84598218239, 0.9977983866899214),\n",
       " 'CFE': (LinearRegression(), 24206.65204181026, 0.9851223450405411),\n",
       " 'CVAE': (LinearRegression(), 22.62728475225067, 0.9999999404110201)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f9846-1692-4264-b1f7-f3da79373a32",
   "metadata": {},
   "source": [
    "#### Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383f6b60-08d1-4e7f-b93c-7d342bcea474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2, X_train, y_train\n",
    "\n",
    "def get_most_important_features(model, X_train, y_train, feature_names):\n",
    "    # Calculate permutation importance\n",
    "    results = permutation_importance(model, X_train, y_train, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Get the importance scores\n",
    "    importance_scores = results.importances_mean\n",
    "    \n",
    "    # Get the sorted indices of features by importance\n",
    "    sorted_indices = np.argsort(importance_scores)[::-1]\n",
    "    \n",
    "    # Create a list of most important features\n",
    "    most_important_features = [feature_names[i] for i in sorted_indices]\n",
    "    \n",
    "    return most_important_features\n",
    "\n",
    "lin_models = {}\n",
    "important_features = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    \n",
    "    model, mse, r2, X_train, y_train = train_evaluate_model(X_data, y_data)\n",
    "    lin_models[tax] = model\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = pred_data[tax].select(pl.all().exclude(target_column)).columns\n",
    "    \n",
    "    # Get the most important features\n",
    "    important_features[tax] = get_most_important_features(model, X_train, y_train, feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c3860-4da6-4377-95c1-5d445c0bdfe2",
   "metadata": {},
   "source": [
    "#### Calculate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6c4ae51-88eb-4a89-8e8c-0fab23c4dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(X_data: pl.DataFrame, y_data: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Ensure y_data has only one column\n",
    "    if y_data.shape[1] != 1:\n",
    "        raise ValueError(\"y_data should only have one column\")\n",
    "    \n",
    "    # Get the name of the single column in y_data\n",
    "    y_column_name = y_data.columns[0]\n",
    "    \n",
    "    # Create an empty list to store the correlation results\n",
    "    correlations = []\n",
    "    \n",
    "    # Calculate correlation for each column in X_data with the y_data column\n",
    "    for col in X_data.columns:\n",
    "        correlation = pl.select(pl.corr(X_data[col], y_data[y_column_name]))\n",
    "        correlations.append((col, *correlation[col]))\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    correlation_df = pl.DataFrame(correlations, schema=[\"Feature\", \"Correlation\"])\n",
    "    \n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b36d24ff-f11e-4bd1-a9e2-82d9a52fb3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lazzz\\AppData\\Local\\Temp\\ipykernel_11932\\1167597072.py:18: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  correlation_df = pl.DataFrame(correlations, schema=[\"Feature\", \"Correlation\"])\n"
     ]
    }
   ],
   "source": [
    "corr_df = {}\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(target_column))\n",
    "    y_data = pred_data[tax].select(target_column)\n",
    "    corr_df[tax] = calculate_correlations(X_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20fd6c-6d20-4f0e-a693-0dc85cd4f834",
   "metadata": {},
   "source": [
    "#### Test without highly correlated columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a33ba-78ef-4786-ac0d-77798bd3d73c",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8433081f-ea45-4fa3-9fff-6318c45b5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate decision tree regressor\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "tree_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    exclude_cols = corr_df[tax].filter(((pl.col('Correlation') < 0.7) & (pl.col('Correlation') > 0.0)))['Feature'].to_list() + [target_column]\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(exclude_cols)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    tree_models[tax] = train_evaluate_model(X_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "490ba11d-f5f9-4eb9-b458-0c4cbf70014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.21%\n",
      "3.95%\n",
      "96.85%\n",
      "99.14%\n",
      "98.51%\n",
      "99.08%\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, (model, mae_test, r2_test, mae_val, r2_val) in tree_models.items():\n",
    "    # print(tax)\n",
    "    # print(f'{mae_val:.0f}')\n",
    "    print(f'{r2_val*100:.2f}%')\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(f\"Test set - MSE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "    # print(f\"Validation set - MSE: {mae_val:.4f}, R2: {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801af94f-4e60-4e6c-852a-d191d429054c",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee23572b-80cb-47dc-87fb-9b776664e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "lin_models = {}\n",
    "\n",
    "for tax, target_column in tax_column_dict.items():\n",
    "    exclude_cols = corr_df[tax].filter(((pl.col('Correlation') < 0.7) & (pl.col('Correlation') > 0.0)))['Feature'].to_list() + [target_column]\n",
    "    X_data = pred_data[tax].select(pl.all().exclude(exclude_cols)).to_numpy()\n",
    "    y_data = pred_data[tax].select(target_column).to_numpy().ravel()\n",
    "    lin_models[tax] = train_evaluate_model(X_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d676eaa-a94e-411f-b73a-aadfa6bf5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339\n",
      "459\n",
      "164840\n",
      "118659\n",
      "21865\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, (model, mae_test, r2_test, mae_val, r2_val) in lin_models.items():\n",
    "    # print(tax)\n",
    "    print(f'{mae_val:.0f}')\n",
    "    # print(f'{r2_test*100:.2f}%')\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(f\"Test set - MSE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "    # print(f\"Validation set - MSE: {mae_val:.4f}, R2: {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6dcf90d4-eddc-47b4-83c6-a98ed8f7f2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (94, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Feature</th><th>Correlation</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;TH - TAUX INTERCOMMUNAL TAXE G…</td><td>-0.052224</td></tr><tr><td>&quot;TH - SYNDICATS ET ORG. ASSIMIL…</td><td>-0.006778</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.010322</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.011104</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.015064</td></tr><tr><td>&quot;TH - INTERCOMMUNALITE / TAUX V…</td><td>0.017563</td></tr><tr><td>&quot;TH - INTERCOMMUNALITE / TAUX A…</td><td>0.023983</td></tr><tr><td>&quot;TH - TSE GRAND PARIS OU EPFL G…</td><td>0.02676</td></tr><tr><td>&quot;TH - TSE / TAUX NET&quot;</td><td>0.02679</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.034545</td></tr><tr><td>&quot;TH - V.L. MOYENNE UTILISEE POU…</td><td>0.040673</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.043811</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.047047</td></tr><tr><td>&quot;TH - V.L. MOYENNE UTILISEE POU…</td><td>0.058268</td></tr><tr><td>&quot;TH - DOTATION (ANCIENS DO)/ RE…</td><td>0.071976</td></tr><tr><td>&quot;TH - SOMME DES ALLOCATIONS COM…</td><td>0.071976</td></tr><tr><td>&quot;TH - V.L. MOYENNE UTILISEE POU…</td><td>0.075564</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.093766</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.094652</td></tr><tr><td>&quot;TH - MONTANT REEL INTERCOMMUNA…</td><td>0.110107</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.115091</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.118948</td></tr><tr><td>&quot;TH - DOTATION (ANCIENS DO) / D…</td><td>0.120591</td></tr><tr><td>&quot;TH - SOMME DES ALLOCATIONS COM…</td><td>0.120591</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.121544</td></tr><tr><td>&quot;TH - SYNDICATS ET ORG. ASSIMIL…</td><td>0.130847</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.155339</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.158471</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.160003</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.164656</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.179589</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.181665</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.19421</td></tr><tr><td>&quot;TH - COMMUNE / TAUX NET&quot;</td><td>0.213075</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS A…</td><td>0.263826</td></tr><tr><td>&quot;TH - NOMBRE D&#x27;ARTICLES PASSIBL…</td><td>0.264517</td></tr><tr><td>&quot;TH - QUOTITE DES ABATTEMENTS  …</td><td>0.266044</td></tr><tr><td>&quot;TH - FRAIS DE GESTION THLV&quot;</td><td>0.267596</td></tr><tr><td>&quot;TH - COMMUNE / PRODUIT REEL DE…</td><td>0.267906</td></tr><tr><td>&quot;TH - EXONERATION REFORME TH AV…</td><td>0.30629</td></tr><tr><td>&quot;TH - TSE GRAND PARIS OU EPFL G…</td><td>0.308707</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE A PART…</td><td>0.324966</td></tr><tr><td>&quot;TH - ABATTEMENT SPECIAL A LA B…</td><td>0.325699</td></tr><tr><td>&quot;TH - TSE GRAND PARIS OU EPFL G…</td><td>0.330028</td></tr><tr><td>&quot;TH - BASE TAXABLE NETTE INTERC…</td><td>0.334414</td></tr><tr><td>&quot;TH - TSE GRAND PARIS OU EPFL G…</td><td>0.335545</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE DE RAN…</td><td>0.347723</td></tr><tr><td>&quot;TH - SYNDICATS ET ORG. ASSIMIL…</td><td>0.373657</td></tr><tr><td>&quot;TH - ABATTEMENT SPECIAL A LA B…</td><td>0.379735</td></tr><tr><td>&quot;TH - REFORME TH  AVEC LISSAGE …</td><td>0.409159</td></tr><tr><td>&quot;TH - SOMME DES ALLOCATIONS COM…</td><td>0.44488</td></tr><tr><td>&quot;TH - ABATTEMENT SPECIAL HANDIC…</td><td>0.46191</td></tr><tr><td>&quot;TH - ABATTEMENT GENERAL A LA B…</td><td>0.463725</td></tr><tr><td>&quot;TH - VL des résidences seconda…</td><td>0.509662</td></tr><tr><td>&quot;TH - V.L. NETTES DES RESIDENCE…</td><td>0.528231</td></tr><tr><td>&quot;TH - ABATTEMENT SPECIAL HANDIC…</td><td>0.591874</td></tr><tr><td>&quot;TH - FRAIS DE GESTION THS&quot;</td><td>0.60187</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE DE RAN…</td><td>0.659242</td></tr><tr><td>&quot;TH - ABATTEMENT GENERAL A LA B…</td><td>0.673735</td></tr><tr><td>&quot;TH - Nombre d&#x27;articles imposés…</td><td>0.682461</td></tr><tr><td>&quot;TH - NOMBRE D&#x27;ARTICLES PASSIBL…</td><td>0.684125</td></tr><tr><td>&quot;TH - COTISATIONS &lt; 12 EUROS (H…</td><td>0.693432</td></tr><tr><td>&quot;TH - COTISATIONS &lt; 12 EUROS (H…</td><td>0.701144</td></tr><tr><td>&quot;TH - V.L. BRUTE  DES LOCAUX DE…</td><td>0.710777</td></tr><tr><td>&quot;TH - VL brute des locaux (hors…</td><td>0.729211</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE A PART…</td><td>0.743487</td></tr><tr><td>&quot;TH - NON-VALEURS HORS REFORME …</td><td>0.756501</td></tr><tr><td>&quot;TH - TSE / MONTANT REEL&quot;</td><td>0.759039</td></tr><tr><td>&quot;TH - NOMBRE DE RESIDENCES SECO…</td><td>0.783004</td></tr><tr><td>&quot;TH - NON-VALEURS HORS REFORME …</td><td>0.785393</td></tr><tr><td>&quot;TH - DEGREVEMENTS GESTIONNAIRE…</td><td>0.798454</td></tr><tr><td>&quot;TH - TSE / NOMBRE D ARTICLES&quot;</td><td>0.812413</td></tr><tr><td>&quot;TH - DEGREVEMENTS GESTIONNAIRE…</td><td>0.831868</td></tr><tr><td>&quot;TH - TSE / BASE NETTE&quot;</td><td>0.832148</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE A PART…</td><td>0.832457</td></tr><tr><td>&quot;TH - BASE EXONEREE TSE / MONTA…</td><td>0.849976</td></tr><tr><td>&quot;TH - PERSONNES A CHARGE DE RAN…</td><td>0.856862</td></tr><tr><td>&quot;TH - BASE EXONEREE TSE / NOMBR…</td><td>0.862616</td></tr><tr><td>&quot;TH - SOMME DES ALLOCATIONS COM…</td><td>0.883236</td></tr><tr><td>&quot;TH - NB ARTICLES AYANT V.L. BR…</td><td>0.8838</td></tr><tr><td>&quot;TH - NOMBRE D ARTICLES PASSIBL…</td><td>0.892199</td></tr><tr><td>&quot;TH - VL brute des locaux (hors…</td><td>0.893688</td></tr><tr><td>&quot;TH - INTERCOMMUNALITE / MONTAN…</td><td>0.904964</td></tr><tr><td>&quot;TH - NOMBRE TOTAL DE PERSONNES…</td><td>0.913486</td></tr><tr><td>&quot;TH - NOMBRE DE PERSONNES A CHA…</td><td>0.920124</td></tr><tr><td>&quot;TH - INTERCOMMUNALITE / BASE N…</td><td>0.924274</td></tr><tr><td>&quot;TH - INTERCOMMUNALITE / NOMBRE…</td><td>0.924693</td></tr><tr><td>&quot;TH - BASES BRUTES EXONEREES (A…</td><td>0.945502</td></tr><tr><td>&quot;TH - BASES NETTES COMMUNALES E…</td><td>0.95266</td></tr><tr><td>&quot;TH - BASES BRUTES EXONEREES (A…</td><td>0.957163</td></tr><tr><td>&quot;TH - NOMBRE D AVIS D IMPOSITIO…</td><td>0.961463</td></tr><tr><td>&quot;TH - COMMUNE / BASE NETTE&quot;</td><td>0.964087</td></tr><tr><td>&quot;TH - COMMUNE / NOMBRE D ARTICL…</td><td>0.964882</td></tr><tr><td>&quot;TH - FRAIS DE GESTION THP-THE&quot;</td><td>0.970725</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (94, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ Feature                         ┆ Correlation │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ TH - TAUX INTERCOMMUNAL TAXE G… ┆ -0.052224   │\n",
       "│ TH - SYNDICATS ET ORG. ASSIMIL… ┆ -0.006778   │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.010322    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.011104    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.015064    │\n",
       "│ TH - INTERCOMMUNALITE / TAUX V… ┆ 0.017563    │\n",
       "│ TH - INTERCOMMUNALITE / TAUX A… ┆ 0.023983    │\n",
       "│ TH - TSE GRAND PARIS OU EPFL G… ┆ 0.02676     │\n",
       "│ TH - TSE / TAUX NET             ┆ 0.02679     │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.034545    │\n",
       "│ TH - V.L. MOYENNE UTILISEE POU… ┆ 0.040673    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.043811    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.047047    │\n",
       "│ TH - V.L. MOYENNE UTILISEE POU… ┆ 0.058268    │\n",
       "│ TH - DOTATION (ANCIENS DO)/ RE… ┆ 0.071976    │\n",
       "│ TH - SOMME DES ALLOCATIONS COM… ┆ 0.071976    │\n",
       "│ TH - V.L. MOYENNE UTILISEE POU… ┆ 0.075564    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.093766    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.094652    │\n",
       "│ TH - MONTANT REEL INTERCOMMUNA… ┆ 0.110107    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.115091    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.118948    │\n",
       "│ TH - DOTATION (ANCIENS DO) / D… ┆ 0.120591    │\n",
       "│ TH - SOMME DES ALLOCATIONS COM… ┆ 0.120591    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.121544    │\n",
       "│ TH - SYNDICATS ET ORG. ASSIMIL… ┆ 0.130847    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.155339    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.158471    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.160003    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.164656    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.179589    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.181665    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.19421     │\n",
       "│ TH - COMMUNE / TAUX NET         ┆ 0.213075    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS A… ┆ 0.263826    │\n",
       "│ TH - NOMBRE D'ARTICLES PASSIBL… ┆ 0.264517    │\n",
       "│ TH - QUOTITE DES ABATTEMENTS  … ┆ 0.266044    │\n",
       "│ TH - FRAIS DE GESTION THLV      ┆ 0.267596    │\n",
       "│ TH - COMMUNE / PRODUIT REEL DE… ┆ 0.267906    │\n",
       "│ TH - EXONERATION REFORME TH AV… ┆ 0.30629     │\n",
       "│ TH - TSE GRAND PARIS OU EPFL G… ┆ 0.308707    │\n",
       "│ TH - PERSONNES A CHARGE A PART… ┆ 0.324966    │\n",
       "│ TH - ABATTEMENT SPECIAL A LA B… ┆ 0.325699    │\n",
       "│ TH - TSE GRAND PARIS OU EPFL G… ┆ 0.330028    │\n",
       "│ TH - BASE TAXABLE NETTE INTERC… ┆ 0.334414    │\n",
       "│ TH - TSE GRAND PARIS OU EPFL G… ┆ 0.335545    │\n",
       "│ TH - PERSONNES A CHARGE DE RAN… ┆ 0.347723    │\n",
       "│ TH - SYNDICATS ET ORG. ASSIMIL… ┆ 0.373657    │\n",
       "│ TH - ABATTEMENT SPECIAL A LA B… ┆ 0.379735    │\n",
       "│ TH - REFORME TH  AVEC LISSAGE … ┆ 0.409159    │\n",
       "│ TH - SOMME DES ALLOCATIONS COM… ┆ 0.44488     │\n",
       "│ TH - ABATTEMENT SPECIAL HANDIC… ┆ 0.46191     │\n",
       "│ TH - ABATTEMENT GENERAL A LA B… ┆ 0.463725    │\n",
       "│ TH - VL des résidences seconda… ┆ 0.509662    │\n",
       "│ TH - V.L. NETTES DES RESIDENCE… ┆ 0.528231    │\n",
       "│ TH - ABATTEMENT SPECIAL HANDIC… ┆ 0.591874    │\n",
       "│ TH - FRAIS DE GESTION THS       ┆ 0.60187     │\n",
       "│ TH - PERSONNES A CHARGE DE RAN… ┆ 0.659242    │\n",
       "│ TH - ABATTEMENT GENERAL A LA B… ┆ 0.673735    │\n",
       "│ TH - Nombre d'articles imposés… ┆ 0.682461    │\n",
       "│ TH - NOMBRE D'ARTICLES PASSIBL… ┆ 0.684125    │\n",
       "│ TH - COTISATIONS < 12 EUROS (H… ┆ 0.693432    │\n",
       "│ TH - COTISATIONS < 12 EUROS (H… ┆ 0.701144    │\n",
       "│ TH - V.L. BRUTE  DES LOCAUX DE… ┆ 0.710777    │\n",
       "│ TH - VL brute des locaux (hors… ┆ 0.729211    │\n",
       "│ TH - PERSONNES A CHARGE A PART… ┆ 0.743487    │\n",
       "│ TH - NON-VALEURS HORS REFORME … ┆ 0.756501    │\n",
       "│ TH - TSE / MONTANT REEL         ┆ 0.759039    │\n",
       "│ TH - NOMBRE DE RESIDENCES SECO… ┆ 0.783004    │\n",
       "│ TH - NON-VALEURS HORS REFORME … ┆ 0.785393    │\n",
       "│ TH - DEGREVEMENTS GESTIONNAIRE… ┆ 0.798454    │\n",
       "│ TH - TSE / NOMBRE D ARTICLES    ┆ 0.812413    │\n",
       "│ TH - DEGREVEMENTS GESTIONNAIRE… ┆ 0.831868    │\n",
       "│ TH - TSE / BASE NETTE           ┆ 0.832148    │\n",
       "│ TH - PERSONNES A CHARGE A PART… ┆ 0.832457    │\n",
       "│ TH - BASE EXONEREE TSE / MONTA… ┆ 0.849976    │\n",
       "│ TH - PERSONNES A CHARGE DE RAN… ┆ 0.856862    │\n",
       "│ TH - BASE EXONEREE TSE / NOMBR… ┆ 0.862616    │\n",
       "│ TH - SOMME DES ALLOCATIONS COM… ┆ 0.883236    │\n",
       "│ TH - NB ARTICLES AYANT V.L. BR… ┆ 0.8838      │\n",
       "│ TH - NOMBRE D ARTICLES PASSIBL… ┆ 0.892199    │\n",
       "│ TH - VL brute des locaux (hors… ┆ 0.893688    │\n",
       "│ TH - INTERCOMMUNALITE / MONTAN… ┆ 0.904964    │\n",
       "│ TH - NOMBRE TOTAL DE PERSONNES… ┆ 0.913486    │\n",
       "│ TH - NOMBRE DE PERSONNES A CHA… ┆ 0.920124    │\n",
       "│ TH - INTERCOMMUNALITE / BASE N… ┆ 0.924274    │\n",
       "│ TH - INTERCOMMUNALITE / NOMBRE… ┆ 0.924693    │\n",
       "│ TH - BASES BRUTES EXONEREES (A… ┆ 0.945502    │\n",
       "│ TH - BASES NETTES COMMUNALES E… ┆ 0.95266     │\n",
       "│ TH - BASES BRUTES EXONEREES (A… ┆ 0.957163    │\n",
       "│ TH - NOMBRE D AVIS D IMPOSITIO… ┆ 0.961463    │\n",
       "│ TH - COMMUNE / BASE NETTE       ┆ 0.964087    │\n",
       "│ TH - COMMUNE / NOMBRE D ARTICL… ┆ 0.964882    │\n",
       "│ TH - FRAIS DE GESTION THP-THE   ┆ 0.970725    │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df['TH'].sort('Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc6034b3-ae0a-4446-ba34-c5c1e417b30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Feature</th><th>Correlation</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Part de CVAE au profit du GFP&quot;</td><td>0.613394</td></tr><tr><td>&quot;Part de CVAE due au profit du …</td><td>0.611458</td></tr><tr><td>&quot;Part de CVAE dégrevée au profi…</td><td>0.608014</td></tr><tr><td>&quot;Part de CVAE exonérée compensé…</td><td>0.021761</td></tr><tr><td>&quot;Part de CVAE au profit du dépa…</td><td>0.437538</td></tr><tr><td>&quot;Part de CVAE due au profit du …</td><td>0.435462</td></tr><tr><td>&quot;Part de CVAE dégrevée au profi…</td><td>0.435169</td></tr><tr><td>&quot;Part de CVAE exonérée compensé…</td><td>0.000104</td></tr><tr><td>&quot;Part de CVAE au profit de la r…</td><td>0.620198</td></tr><tr><td>&quot;Part de CVAE due au profit de …</td><td>0.618128</td></tr><tr><td>&quot;Part de CVAE dégrevée au profi…</td><td>0.617003</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ Feature                         ┆ Correlation │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ Part de CVAE au profit du GFP   ┆ 0.613394    │\n",
       "│ Part de CVAE due au profit du … ┆ 0.611458    │\n",
       "│ Part de CVAE dégrevée au profi… ┆ 0.608014    │\n",
       "│ Part de CVAE exonérée compensé… ┆ 0.021761    │\n",
       "│ Part de CVAE au profit du dépa… ┆ 0.437538    │\n",
       "│ Part de CVAE due au profit du … ┆ 0.435462    │\n",
       "│ Part de CVAE dégrevée au profi… ┆ 0.435169    │\n",
       "│ Part de CVAE exonérée compensé… ┆ 0.000104    │\n",
       "│ Part de CVAE au profit de la r… ┆ 0.620198    │\n",
       "│ Part de CVAE due au profit de … ┆ 0.618128    │\n",
       "│ Part de CVAE dégrevée au profi… ┆ 0.617003    │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df['CVAE'].filter(((pl.col('Correlation')<0.8) & (pl.col('Correlation')>0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a883d829-0204-40ee-903a-6aab64a07ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FNB': (LinearRegression(), 69660150.01043834, 0.954765801300399),\n",
       " 'TAFNB': (LinearRegression(), 5818611.77202496, 0.019531322371426296),\n",
       " 'FB': (LinearRegression(), 875282029282.2172, 0.9780925972698389),\n",
       " 'TH': (LinearRegression(), 7452630410263.093, 0.951195560483361),\n",
       " 'CFE': (LinearRegression(), 11716629769.860273, 0.9997405567589526),\n",
       " 'CVAE': (LinearRegression(), 356555.6092389835, 0.9999999517788819)}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf0e90-8aeb-4fc5-abf3-ad5abfdf1171",
   "metadata": {},
   "source": [
    "# Future years prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86791f3-b90f-4c7c-b867-31fcf75a7287",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e23e1f55-d4a6-4bef-8a46-0ce6292e0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_pred_data = {}\n",
    "for tax, columns in dict_col_prediction.items():\n",
    "    year_pred_data[tax] = francetax.select(*basic_columns, 'ANNEE', *columns).with_columns([\n",
    "    create_insee_code(commune_code['DEPARTEMENT'], commune_code['COMMUNE']).alias(\"code INSEE\")\n",
    "]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7299fb73-dbe6-417a-bca4-57e3ac532841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null_columns(df: pl.DataFrame, threshold: float = 0.5) -> list:\n",
    "    total_rows = df.height\n",
    "    null_counts = df.null_count().unpivot()\n",
    "    \n",
    "    result = (\n",
    "        null_counts\n",
    "        .filter(pl.col('value') / total_rows > threshold)\n",
    "        .select('variable')\n",
    "        .to_series()\n",
    "        .to_list()\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c088dc84-d97e-4a74-a7d8-aa1d2aae542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with completeness < 80%\n",
    "for tax, data in year_pred_data.items():\n",
    "    for i in find_null_columns(data, 0.8):\n",
    "        data.drop_in_place(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c16b05d-dfb4-4511-99ec-39b26b4d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax, data in year_pred_data.items():\n",
    "    # Identify columns with Utf8 dtype\n",
    "    utf8_columns = [col for col in data.columns if data[col].dtype == pl.Utf8]\n",
    "    utf8_columns.remove('Commune name')\n",
    "    utf8_columns.remove('DEPARTEMENT')\n",
    "    utf8_columns.remove('code INSEE')\n",
    "    utf8_columns.remove('COMMUNE')\n",
    "    # if tax == 'TEOM':\n",
    "    #     utf8_columns.remove('Bénéficiaire de la TEOM (C, I, P ou S)')\n",
    "    #     utf8_columns.remove('Libellé du syndicat TEOM')\n",
    "    #     utf8_columns.remove('NUMERO SIREN DU SYNDICAT TEOM')\n",
    "    # Apply transformations to all relevant columns\n",
    "    try:\n",
    "        year_pred_data[tax] = data.with_columns([\n",
    "            pl.when(pl.col(col).is_in([\".\", \"'\", \",\"]))\n",
    "            .then(None)\n",
    "            .otherwise(\n",
    "                pl.col(col)\n",
    "                .str.replace(',', '.')\n",
    "                \n",
    "            ).alias(col).cast(pl.Float64)\n",
    "            for col in utf8_columns\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tax}: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "418f4aa9-7379-4acb-ac19-ffd84178cb26",
   "metadata": {},
   "source": [
    "for tax, target_column in zip(tax_types, y_columns):\n",
    "    for i in range(1, 3):\n",
    "   # Add the new TARGET column to the original DataFrame\n",
    "        year_pred_data[tax] = year_pred_data[tax].join(year_pred_data[tax].with_columns(\n",
    "            pl.col(target_column).alias(f'TARGET-{i}'),\n",
    "            (pl.col('ANNEE') - i).alias('ANNEE'),  # Include the ANNEE column, shifted by 1\n",
    "            pl.col('code INSEE')\n",
    "        ), on=['code INSEE', 'ANNEE'], how='left')\n",
    "        year_pred_data[tax] = year_pred_data[tax].select(\n",
    "    [pl.col(col) for col in year_pred_data[tax].columns if not col.endswith('_right')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6827eca1-ad69-4594-8693-094bda4d41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_years = 3\n",
    "for tax, target_column in zip(tax_types, y_columns):\n",
    "    for i in range(1, target_years + 1):\n",
    "        # Prepare the shifted year DataFrame\n",
    "        shifted_df = year_pred_data[tax].select([\n",
    "            pl.col('code INSEE'),\n",
    "            (pl.col('ANNEE') - i).alias('ANNEE'),\n",
    "            pl.col(target_column).alias(f'TARGET-{i}')\n",
    "        ])\n",
    "        \n",
    "        # Perform the join operation\n",
    "        year_pred_data[tax] = year_pred_data[tax].join(\n",
    "            shifted_df,\n",
    "            on=['code INSEE', 'ANNEE'],\n",
    "            how='left'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a24b07-02dd-404c-871f-198012d27470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax in tax_types:\n",
    "    # year_pred_data[tax] = year_pred_data[tax].select(pl.all().exclude('Commune name',\t'DEPARTEMENT', 'COMMUNE', 'code INSEE'))\n",
    "    year_pred_data[tax] = year_pred_data[tax].drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54e397f4-19da-4d8f-8441-8fbe3f6686ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "year_lin_models = {}\n",
    "\n",
    "for tax, data in year_pred_data.items():\n",
    "    year_lin_models[tax] = []\n",
    "    for i in range(1, target_years + 1):\n",
    "        exclude_cols = [f'TARGET-{j}' for j in range(1, target_years + 1) if j != i] + [*basic_columns, 'code INSEE']\n",
    "        df = data.select(pl.all().exclude(exclude_cols)).drop_nulls()\n",
    "        X_data = df.select(pl.all().exclude('^TARGET.*$')).to_numpy()\n",
    "        y_data = df.select(f'TARGET-{i}').to_numpy().ravel()\n",
    "        year_lin_models[tax] += [train_evaluate_model(X_data, y_data)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f6ba8cf-36db-4bdc-a2a9-deee952eec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.48 94.97 94.16 \n",
      "74.74 53.48 47.39 \n",
      "99.88 88.03 97.35 \n",
      "99.91 98.34 99.61 \n",
      "-2152386.62 75.39 88.18 \n",
      "51.53 -12889.78 -31225.98 \n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, results in year_lin_models.items():\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(tax)\n",
    "    r_prt =''\n",
    "    for i, (model, mae_test, r2_test, mae_val, r2_val) in enumerate(results, 1):\n",
    "        r_prt += f'{r2_val*100:.2f} '\n",
    "        \n",
    "    print(f'{r_prt}')\n",
    "        \n",
    "        # print(f\"TARGET-{i} - Test set - MAE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "        # print(f\"TARGET-{i} - Validation set - MAE: {mae_val:.4f}, R2: {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f55bd81-91ed-4059-80b8-38ece2022e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for FNB:\n",
      "TARGET-1 - Test set - MAE: 470.7690, R2: 0.9757\n",
      "TARGET-1 - Validation set - MAE: 470.1492, R2: 0.9666\n",
      "TARGET-2 - Test set - MAE: 579.9401, R2: 0.9725\n",
      "TARGET-2 - Validation set - MAE: 647.1596, R2: 0.9587\n",
      "TARGET-3 - Test set - MAE: 727.8891, R2: 0.9602\n",
      "TARGET-3 - Validation set - MAE: 731.3051, R2: 0.9619\n",
      "\n",
      "Results for TAFNB:\n",
      "TARGET-1 - Test set - MAE: 54.9145, R2: 0.7515\n",
      "TARGET-1 - Validation set - MAE: 48.5281, R2: 0.8572\n",
      "TARGET-2 - Test set - MAE: 66.7570, R2: 0.6538\n",
      "TARGET-2 - Validation set - MAE: 63.1176, R2: 0.8168\n",
      "TARGET-3 - Test set - MAE: 68.0825, R2: 0.5865\n",
      "TARGET-3 - Validation set - MAE: 63.7053, R2: 0.7460\n",
      "\n",
      "Results for FB:\n",
      "TARGET-1 - Test set - MAE: 5424.0532, R2: 0.9996\n",
      "TARGET-1 - Validation set - MAE: 5181.0302, R2: 0.9998\n",
      "TARGET-2 - Test set - MAE: 11397.3207, R2: 0.9990\n",
      "TARGET-2 - Validation set - MAE: 21206.5224, R2: 0.9872\n",
      "TARGET-3 - Test set - MAE: 25576.2876, R2: 0.9204\n",
      "TARGET-3 - Validation set - MAE: 15302.1511, R2: 0.9977\n",
      "\n",
      "Results for TH:\n",
      "TARGET-1 - Test set - MAE: 541248.2962, R2: 0.9263\n",
      "TARGET-1 - Validation set - MAE: 668627.9423, R2: 0.8987\n",
      "TARGET-2 - Test set - MAE: 240850.0692, R2: 0.9949\n",
      "TARGET-2 - Validation set - MAE: 207331.2628, R2: 0.9950\n",
      "TARGET-3 - Test set - MAE: 897487.9077, R2: 0.7243\n",
      "TARGET-3 - Validation set - MAE: 1398108.8718, R2: 0.6636\n",
      "\n",
      "Results for CFE:\n",
      "TARGET-1 - Test set - MAE: 641.2700, R2: 0.9995\n",
      "TARGET-1 - Validation set - MAE: 799.1055, R2: 0.9853\n",
      "TARGET-2 - Test set - MAE: 1521.8017, R2: 0.9542\n",
      "TARGET-2 - Validation set - MAE: 3016.3257, R2: 0.8787\n",
      "TARGET-3 - Test set - MAE: 1652.6295, R2: 0.9895\n",
      "TARGET-3 - Validation set - MAE: 1711.3188, R2: 0.8951\n",
      "\n",
      "Results for CVAE:\n",
      "TARGET-1 - Test set - MAE: 1180.6754, R2: 0.9998\n",
      "TARGET-1 - Validation set - MAE: 1493.3582, R2: 0.8641\n",
      "TARGET-2 - Test set - MAE: 1235.5919, R2: 0.8537\n",
      "TARGET-2 - Validation set - MAE: 8032.1837, R2: 0.0824\n",
      "TARGET-3 - Test set - MAE: 1160.0438, R2: 1.0000\n",
      "TARGET-3 - Validation set - MAE: 1265.2165, R2: 0.8017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Function to train and evaluate decision tree regression\n",
    "def train_evaluate_model(X, y):\n",
    "    \n",
    "    # First split: separate validation set\n",
    "    X_temp, X_val, y_temp, y_val = train_test_split(X, y, test_size=0.15)\n",
    "    \n",
    "    # Second split: separate train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2941)\n",
    "    # 0.2941 ensures that test set is 25% of the total data (0.25 / 0.85 = 0.2941)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    return model, mae_test, r2_test, mae_val, r2_val\n",
    "\n",
    "year_tree_models = {}\n",
    "\n",
    "for tax, data in year_pred_data.items():\n",
    "    year_tree_models[tax] = []\n",
    "    for i in range(1, target_years + 1):\n",
    "        exclude_cols = [f'TARGET-{j}' for j in range(1, target_years + 1) if j != i] + [*basic_columns, 'code INSEE']\n",
    "        df = data.select(pl.all().exclude(exclude_cols)).drop_nulls()\n",
    "        X_data = df.select(pl.all().exclude('^TARGET.*$')).to_numpy()\n",
    "        y_data = df.select(f'TARGET-{i}').to_numpy().ravel()\n",
    "        year_tree_models[tax] += [train_evaluate_model(X_data, y_data)]\n",
    "\n",
    "# Print results\n",
    "for tax, results in year_tree_models.items():\n",
    "    print(f\"\\nResults for {tax}:\")\n",
    "    for i, (model, mae_test, r2_test, mae_val, r2_val) in enumerate(results, 1):\n",
    "        print(f\"TARGET-{i} - Test set - MAE: {mae_test:.4f}, R2: {r2_test:.4f}\")\n",
    "        print(f\"TARGET-{i} - Validation set - MAE: {mae_val:.4f}, R2: {r2_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bce1ebc-4a17-42c9-b311-78ee233e25dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.66, 95.87, 96.19, \n",
      "85.72, 81.68, 74.60, \n",
      "99.98, 98.72, 99.77, \n",
      "89.87, 99.50, 66.36, \n",
      "98.53, 87.87, 89.51, \n",
      "86.41, 8.24, 80.17, \n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for tax, results in year_tree_models.items():\n",
    "    # print(f\"\\nResults for {tax}:\")\n",
    "    # print(tax)\n",
    "    r_prt =''\n",
    "    for i, (model, mae_test, r2_test, mae_val, r2_val) in enumerate(results, 1):\n",
    "        r_prt += f'{r2_val*100:.2f}, '\n",
    "        \n",
    "    print(f'{r_prt}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0bcdb33-04f8-44f7-98f9-65754a9e137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to train and evaluate linear regression\n",
    "def train_evaluate_model(X, y):\n",
    "        \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "year_lin_models = {}\n",
    "\n",
    "for tax, data in year_pred_data.items():\n",
    "    year_lin_models[tax] = []\n",
    "    for i in range(1, target_years + 1):\n",
    "        exclude_cols = [f'TARGET-{j}' for j in range(1, target_years + 1) if j != i] + [*basic_columns, 'code INSEE']\n",
    "        df = data.select(pl.all().exclude(exclude_cols)).drop_nulls()\n",
    "        X_data = df.select(pl.all().exclude('^TARGET.*$'))\n",
    "        y_data = df.select(f'TARGET-{i}')\n",
    "        year_lin_models[tax] += [train_evaluate_model(X_data, y_data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490b25d-3534-4120-8547-08d7ae70baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_lin_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ac633-8a08-4ee8-b6ef-e5daedbfb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_correlations(year_pred_data['TH'], year_pred_data['TH'].select(f'TARGET-2')).filter(pl.col('Correlation').is_not_nan()).sort('Correlation', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bef22-5a60-4e52-9b4e-311b32880280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
